{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from model_testing.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model_testing\n",
    "\n",
    "> A library to test fastai learners using some evaluation techniques.\n",
    "\n",
    "This library will allow you to easily evaluate your `fastai` `Learner`s using different evaluation techinique such as `KFold-validation` or `StratifiedKFold-Validation`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install the library, just run:\n",
    "\n",
    "```sh\n",
    "pip install model_testing\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This library provides a method that can help you in the process of model evaluation. Using the [scikit-learn validation techniques](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators) you can validate your deep learning models.\n",
    "\n",
    "In order to validate your model, you will need to build and train various versions of it (for example, using a KFold validation, it is needed to build five different models).\n",
    "\n",
    "For doing so, you need to provide: the `DataBlock` hparams (hyperparameters), the `DataLoader` hparams, the technique used to split the data, the `Learner` construction hparams, the learning mode (whether to use a pretrained model or not: `fit_one_cycle` or `finetune`) and the `Learner` training hparams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "dataset/codesAll.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_y_fn\u001b[39m (x):\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Path(\u001b[38;5;28mstr\u001b[39m(x)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImages\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m---> 21\u001b[0m codes \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcodesAll.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mParentSplitter\u001b[39m(x):\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Path(x)\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m==\u001b[39mtest_name\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/npyio.py:961\u001b[0m, in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m    959\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os_fspath(fname)\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_string_like(fname):\n\u001b[0;32m--> 961\u001b[0m     fh \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_datasource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    962\u001b[0m     fencoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(fh, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    963\u001b[0m     fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(fh)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/_datasource.py:195\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;124;03mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    191\u001b[0m \n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    194\u001b[0m ds \u001b[38;5;241m=\u001b[39m DataSource(destpath)\n\u001b[0;32m--> 195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/lib/_datasource.py:535\u001b[0m, in \u001b[0;36mDataSource.open\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m    533\u001b[0m                               encoding\u001b[38;5;241m=\u001b[39mencoding, newline\u001b[38;5;241m=\u001b[39mnewline)\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 535\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m path)\n",
      "\u001b[0;31mOSError\u001b[0m: dataset/codesAll.txt not found."
     ]
    }
   ],
   "source": [
    "from fastai.basics import *\n",
    "from fastai.vision import models\n",
    "from fastai.vision.all import *\n",
    "from fastai.metrics import *\n",
    "from fastai.data.all import *\n",
    "from fastai.callback import *\n",
    "\n",
    "import PIL\n",
    "import torchvision.transforms as transforms\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "path = Path('dataset/')\n",
    "path_images = path/\"Images\"\n",
    "path_labels = path/\"Labels\"\n",
    "test_name = \"test\"\n",
    "\n",
    "def get_y_fn (x):\n",
    "    return Path(str(x).replace(\"Images\",\"Labels\").replace(\"color\",\"gt\").replace(\".jpg\",\".png\"))\n",
    "\n",
    "codes = np.loadtxt(path/'codesAll.txt', dtype=str)\n",
    "\n",
    "def ParentSplitter(x):\n",
    "    return Path(x).parent.name==test_name\n",
    "\n",
    "from albumentations import (\n",
    "  Compose,\n",
    "  OneOf,\n",
    "  ElasticTransform,\n",
    "  GridDistortion, \n",
    "  OpticalDistortion,\n",
    "  HorizontalFlip,\n",
    "  Rotate,\n",
    "  Transpose,\n",
    "  CLAHE,\n",
    "  ShiftScaleRotate\n",
    ")\n",
    "\n",
    "class SegmentationAlbumentationsTransform(ItemTransform):\n",
    "    split_idx = 0\n",
    "\n",
    "    def __init__(self, aug): \n",
    "        self.aug = aug\n",
    "\n",
    "    def encodes(self, x):\n",
    "        img,mask = x\n",
    "        aug = self.aug(image=np.array(img), mask=np.array(mask))\n",
    "        return PILImage.create(aug[\"image\"]), PILMask.create(aug[\"mask\"])\n",
    "\n",
    "transforms=Compose([HorizontalFlip(p=0.5),\n",
    "                    Rotate(p=0.40,limit=10),GridDistortion()\n",
    "                    ],p=1)\n",
    "\n",
    "transformPipeline=SegmentationAlbumentationsTransform(transforms)\n",
    "\n",
    "class TargetMaskConvertTransform(ItemTransform):\n",
    "    def __init__(self): \n",
    "        pass\n",
    "\n",
    "    def encodes(self, x):\n",
    "        img,mask = x\n",
    "\n",
    "        #Convert to array\n",
    "        mask = np.array(mask)\n",
    "\n",
    "        # background = 0, leaves = 1, pole = 74 o 76, wood = 25 o 29, grape = 255\n",
    "        mask[mask == 255] = 1 # grape\n",
    "        mask[mask == 150] = 2 # leaves\n",
    "        mask[mask == 76] = 3 ; mask[mask == 74] = 3 # pole\n",
    "        mask[mask == 29] = 4 ; mask[mask == 25] = 4 # wood\n",
    "        mask[mask >= 5] = 0 # resto: background\n",
    "\n",
    "        # Back to PILMask\n",
    "        mask = PILMask.create(mask)\n",
    "        return img, mask\n",
    "\n",
    "trainDB = DataBlock(blocks=(ImageBlock, MaskBlock(codes)),\n",
    "                   get_items=partial(get_image_files,folders=['train']),\n",
    "                   get_y=get_y_fn,\n",
    "                   splitter=RandomSplitter(valid_pct=0.2),\n",
    "                   item_tfms=[Resize((480,640)), TargetMaskConvertTransform(), transformPipeline],\n",
    "                   batch_tfms=Normalize.from_stats(*imagenet_stats)\n",
    "                  )\n",
    "\n",
    "testDB = DataBlock(blocks=(ImageBlock, MaskBlock(codes)),\n",
    "                   get_items=partial(get_image_files,folders=['train','test']),\n",
    "                   get_y=get_y_fn,\n",
    "                   splitter=FuncSplitter(ParentSplitter),\n",
    "                   item_tfms=[Resize((480,640)), TargetMaskConvertTransform(), transformPipeline],\n",
    "                   batch_tfms=Normalize.from_stats(*imagenet_stats)\n",
    "                  )\n",
    "\n",
    "bs = 4\n",
    "trainDLS = trainDB.dataloaders(path_images,bs=bs)\n",
    "testDLS = testDB.dataloaders(path_images,bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
